# my global config
global:
  #scrape_interval: 5m # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 1m # Evaluate rules every 15 seconds. The default is every 1 minute.
  scrape_timeout: 50s
# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"
    scheme: "https"
    tls_config:
      ca_file: "C:\\cert\\cert.cer"
    static_configs:
      - targets: ["prometheus.steviecoaster.dev:9090"]

  - job_name: "chocoserver"
    scheme: "http"
    static_configs:
      - targets: ["chocoserver.steviecoaster.dev:9182"]

  - job_name: 'snmp'        # Query devices over SNMP
    static_configs:
      - targets:  ["192.168.1.20"]
        labels:
          job: 'brother_printer'
    metrics_path: /snmp
    params:
      module: [printer_mib]
    relabel_configs:
     - source_labels: [__address__]
       target_label: __param_target
     - source_labels: [__param_target]
       target_label: instance
     - target_label: __address__
       replacement: 'promserver:9116' #Hostname/IP of the snmp_exporter